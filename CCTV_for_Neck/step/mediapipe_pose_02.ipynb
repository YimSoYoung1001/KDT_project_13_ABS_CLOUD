{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T05:52:13.967504Z",
     "start_time": "2024-04-27T05:52:13.951869Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import math\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일의 경우 이것을 사용하세요.:\n",
    "\n",
    "# IMAGE_FILES = []\n",
    "# BG_COLOR = (192, 192, 192)  # 회색\n",
    "# with mp_pose.Pose(\n",
    "#         static_image_mode=True,\n",
    "#         model_complexity=2,\n",
    "#         enable_segmentation=True,\n",
    "#         min_detection_confidence=0.5) as pose:\n",
    "#     for idx, file in enumerate(IMAGE_FILES):\n",
    "#         image = cv2.imread(file)\n",
    "#         image_height, image_width, _ = image.shape\n",
    "#         # 처리 전 BGR 이미지를 RGB로 변환합니다.\n",
    "#         results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#         if not results.pose_landmarks:\n",
    "#             continue\n",
    "#         print(\n",
    "#             f'Nose coordinates: ('\n",
    "#             f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width}, '\n",
    "#             f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_height})'\n",
    "#         )\n",
    "\n",
    "#         annotated_image = image.copy()\n",
    "#         # 이미지를 분할합니다.\n",
    "#         # 경계 주변의 분할을 개선하려면 \"image\"가 있는\n",
    "#         # \"results.segmentation_mask\"에 공동 양방향 필터를 적용하는 것이 좋습니다.\n",
    "#         condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "#         bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "#         bg_image[:] = BG_COLOR\n",
    "#         annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "#         # 이미지 위에 포즈 랜드마크를 그립니다.\n",
    "#         mp_drawing.draw_landmarks(\n",
    "#             annotated_image,\n",
    "#             results.pose_landmarks,\n",
    "#             mp_pose.POSE_CONNECTIONS,\n",
    "#             landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "#         cv2.imwrite('/tmp/annotated_image' +\n",
    "#                     str(idx) + '.png', annotated_image)\n",
    "#         # 포즈 월드 랜드마크를 그립니다.\n",
    "#         mp_drawing.plot_landmarks(\n",
    "#             results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T05:52:13.999560Z",
     "start_time": "2024-04-27T05:52:13.983466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 부위가 몸의 어떤 부위와 연결되어있는지 알 수 있다.\n",
    "mp_pose.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠, 영상 파일에서 자세 감지\n",
    "# 좌표 있는 버전 \n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_pose.Pose(\n",
    "#         min_detection_confidence=0.5,\n",
    "#         min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         success, image = cap.read()\n",
    "#         if not success:\n",
    "#             print(\"카메라를 찾을 수 없습니다.\")\n",
    "#             # 동영상을 불러올 경우는 'continue' 대신 'break'를 사용합니다.\n",
    "#             continue\n",
    "\n",
    "#         # 필요에 따라 성능 향상을 위해 이미지 작성을 불가능함으로 기본 설정합니다.\n",
    "#         image.flags.writeable = False\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         results = pose.process(image)\n",
    "\n",
    "#         # 포즈의 좌표값을 화면에 같이 나타내기\n",
    "#         if results.pose_landmarks:\n",
    "#             lip_9 = int(results.pose_landmarks.landmark[9].x * 100)\n",
    "#             lip_10 = int(results.pose_landmarks.landmark[10].x * 100)\n",
    "#             shoulder_11 = int(results.pose_landmarks.landmark[11].x * 100)\n",
    "#             shoulder_12 = int(results.pose_landmarks.landmark[12].x * 100)\n",
    "#             cv2.putText(\n",
    "#                 image,\n",
    "#                 text=f\"leftlp({lip_9}) rightlp({lip_10}) leftshd({shoulder_11}) rightshd({shoulder_12})\",\n",
    "#                 org=(10, 30),\n",
    "#                 fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "#                 fontScale=1,\n",
    "#                 color=255,\n",
    "#                 thickness=1\n",
    "#             )\n",
    "\n",
    "#         # 포즈 주석을 이미지 위에 그립니다.\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "#         mp_drawing.draw_landmarks(\n",
    "#             image,\n",
    "#             results.pose_landmarks,\n",
    "#             mp_pose.POSE_CONNECTIONS,\n",
    "#             landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        \n",
    "#         # 보기 편하게 이미지를 좌우 반전합니다.\n",
    "#         cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))\n",
    "\n",
    "\n",
    "#         if cv2.waitKey(1) == ord('q'): break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - nose\n",
    "1 - left eye (inner)\n",
    "2 - left eye\n",
    "3 - left eye (outer)\n",
    "4 - right eye (inner)\n",
    "5 - right eye\n",
    "6 - right eye (outer)\n",
    "7 - left ear\n",
    "8 - right ear\n",
    "9 - mouth (left)\n",
    "10 - mouth (right)\n",
    "11 - left shoulder\n",
    "12 - right shoulder\n",
    "13 - left elbow\n",
    "14 - right elbow\n",
    "15 - left wrist\n",
    "16 - right wrist\n",
    "17 - left pinky\n",
    "18 - right pinky\n",
    "19 - left index\n",
    "20 - right index\n",
    "21 - left thumb\n",
    "22 - right thumb\n",
    "23 - left hip\n",
    "24 - right hip\n",
    "25 - left knee\n",
    "26 - right knee\n",
    "27 - left ankle\n",
    "28 - right ankle\n",
    "29 - left heel\n",
    "30 - right heel\n",
    "31 - left foot index\n",
    "32 - right foot index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 거북목 진행상태 확인\n",
    "- https://brunch.co.kr/@seiyeon119/208\n",
    "- 이미 거북목이 진행된 상태 : 귀 중간부터 어깨 중앙선까지 수직선을 그렸을 때 고개가 앞으로 2.5cm 이상 떨어져있다면 \n",
    "- 거묵목 교정이 필요한 상태 : 귀 중간부터 어깨 중앙선까지 수직선을 그렸을 때 고개가 앞으로 5cm 이상 떨어져있다면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T05:52:14.046577Z",
     "start_time": "2024-04-27T05:52:14.030572Z"
    }
   },
   "outputs": [],
   "source": [
    "def pointDist(x1,y1,z1,x2,y2,z2):\n",
    "    class Point3D:\n",
    "        def __init__(self,x,y,z):\n",
    "            self.x=x\n",
    "            self.y=y\n",
    "            self.z=z\n",
    "    p1=Point3D(x=x1,y=y1,z=z1)\n",
    "    p2=Point3D(x=x2,y=y2,z=z2)\n",
    "    dist=math.sqrt(pow(p2.x-p1.x,2)+pow(p2.y-p1.y,2)+pow(p2.z-p1.z,2))\n",
    "    # print(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A4 paper width in pixels: 391\n",
      "A4 paper real width: 21.0 cm\n"
     ]
    }
   ],
   "source": [
    "# A4 탐지\n",
    "# 세로로 들어야함 그래야 width로 저장됨\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"비디오 파일을 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# A4의 높이값 반환해주는 함수\n",
    "def detect_a4_paper(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)\n",
    "        if len(approx) == 4:\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            aspect_ratio = float(w) / h\n",
    "            if 0.7 < aspect_ratio < 1.4 and w > 100 and h > 100:\n",
    "                return w\n",
    "    return None\n",
    "\n",
    "\n",
    "while True:\n",
    "    # 비디오 프레임 읽기\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"카메라를 찾을 수 없습니다.\")\n",
    "        # 동영상을 불러올 경우는 'continue' 대신 'break'를 사용합니다.\n",
    "        continue\n",
    "\n",
    "    # 프레임 화면에 표시\n",
    "    cv2.imshow('camera', image) \n",
    "\n",
    "    ref_pixel_width = detect_a4_paper(image)\n",
    "    if ref_pixel_width is not None:\n",
    "        # 기준 물체의 실제 크기와 픽셀 크기 (예: A4 용지)\n",
    "        ref_real_width = 21.0  # cm, A4 용지의 실제 가로 길이\n",
    "        print(f\"A4 paper width in pixels: {ref_pixel_width}\")\n",
    "        print(f\"A4 paper real width: {ref_real_width} cm\")\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T05:53:04.275010Z",
     "start_time": "2024-04-27T05:52:14.046577Z"
    }
   },
   "outputs": [],
   "source": [
    "# 웹캠, 영상 파일에서 자세 감지\n",
    "# 귀와 어깨 중앙선까지의 수직선의 거리 구하기\n",
    "# 좌표 있는 버전 \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라를 찾을 수 없습니다.\")\n",
    "            # 동영상을 불러올 경우는 'continue' 대신 'break'를 사용합니다.\n",
    "            continue\n",
    "\n",
    "        # 필요에 따라 성능 향상을 위해 이미지 작성을 불가능함으로 기본 설정합니다.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "        \n",
    "\n",
    "        # x, y 는 [0.0, 1.0]으로 정규화됨\n",
    "        # z 는 엉덩이 중간 지점의 깊이를 원점으로 하는 랜드마크의 깊이 나타냄 \n",
    "\n",
    "        img_h, img_w, _ = image.shape\n",
    "        focal_length = 1 * img_w\n",
    "\n",
    "        # 픽셀 대 cm 비율 계산\n",
    "        pixel_to_cm_ratio = ref_real_width / ref_pixel_width\n",
    "\n",
    "        e_left_x = int(results.pose_landmarks.landmark[7].x * img_w)\n",
    "        e_left_y = int(results.pose_landmarks.landmark[7].y * img_h)\n",
    "        e_left_z = results.pose_landmarks.landmark[7].z * focal_length\n",
    "\n",
    "        e_right_x = int(results.pose_landmarks.landmark[8].x * img_w)\n",
    "        e_right_y = int(results.pose_landmarks.landmark[8].y * img_h)\n",
    "        e_right_z = results.pose_landmarks.landmark[8].z * focal_length\n",
    "\n",
    "        s_left_x = int(results.pose_landmarks.landmark[11].x * img_w)\n",
    "        s_left_y = int(results.pose_landmarks.landmark[11].y * img_h)\n",
    "        s_left_z = results.pose_landmarks.landmark[11].z * focal_length\n",
    "\n",
    "        s_right_x = int(results.pose_landmarks.landmark[12].x * img_w)\n",
    "        s_right_y = int(results.pose_landmarks.landmark[12].y * img_h)\n",
    "        s_right_z = results.pose_landmarks.landmark[12].z * focal_length\n",
    "\n",
    "        # 귀와 어깨 사이 거리값 구하기 (픽셀 단위)\n",
    "        left_dist_pixel = pointDist(e_left_x, e_left_y, e_left_z, s_left_x, s_left_y, s_left_z)\n",
    "        right_dist_pixel = pointDist(e_right_x, e_right_y, e_right_z, s_right_x, s_right_y, s_right_z)\n",
    "\n",
    "        # 거리값을 cm 단위로 변환\n",
    "        left_dist_cm = round(left_dist_pixel * pixel_to_cm_ratio, 3)\n",
    "        right_dist_cm = round(right_dist_pixel * pixel_to_cm_ratio, 3)\n",
    "\n",
    "        # 변환된 거리값을 이미지에 출력\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            text=f\"left D {left_dist_cm} cm, right D {right_dist_cm} cm\",\n",
    "            org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "            fontScale=2,\n",
    "            color=(0, 255, 0),\n",
    "            thickness=2\n",
    "        )\n",
    "\n",
    "        # 포즈 주석을 이미지 위에 그립니다.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        \n",
    "        # 보기 편하게 이미지를 좌우 반전합니다.\n",
    "        cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))\n",
    "        \n",
    "        # 알림창 표시\n",
    "        # if (left_dist_cm >= 2.5) or (right_dist_cm >= 2.5):\n",
    "        #     pyautogui.alert(text = 'Excuse me, you should sit up straight.',\n",
    "        #                     title = 'Knock Knock',\n",
    "        #                     button = 'got it',\n",
    "        #                     timeout=2000)   # 2초 후 time out\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T05:53:04.277498Z",
     "start_time": "2024-04-27T05:53:04.277498Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
